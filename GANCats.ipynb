{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2473b574",
   "metadata": {},
   "source": [
    "# This Cat Doesn't Exist\n",
    "## Generative Adversarial Networks Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699eef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f387e",
   "metadata": {},
   "source": [
    "# Dataset Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RUN THIS CODE ONLY IF YOU ARE ON GOOGLE COLAB! ########\n",
    "###### OTHERWISE, YOU SHOULD DELETE THIS CELL!!       ########\n",
    "!wget https://github.com/ursinus-cs477-f2023/HW7_GAN/archive/refs/heads/main.zip\n",
    "!unzip main.zip\n",
    "!mv HW7_GAN-main/cats .\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(XGen):\n",
    "    \"\"\"\n",
    "    Plot a set of examples from the dataset/generator on a square grid\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    XGen: torch.tensor(n_examples, 3, dim, dim)\n",
    "        A batch of examples to plot\n",
    "    \"\"\"\n",
    "    k = int(np.sqrt(XGen.shape[0]))\n",
    "    for i in range(XGen.shape[0]):\n",
    "        plt.subplot(k, k, i+1)\n",
    "        Xi = XGen[i, :, :, :].detach().cpu().numpy()\n",
    "        Xi = np.moveaxis(Xi, 0, 2)\n",
    "        Xi[Xi < 0] = 0\n",
    "        Xi[Xi > 1] = 1\n",
    "        plt.imshow(Xi)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "class CatData(Dataset):\n",
    "    def __init__(self, foldername, imgres=64, train=True):\n",
    "        self.images = glob.glob(\"{}/*\".format(foldername))\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.Resize(imgres),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.images[idx])\n",
    "        img = self.preprocess(img)\n",
    "        if torch.max(img) > 1:\n",
    "            img /= 255\n",
    "        return img\n",
    "    \n",
    "traindata = CatData(\"cats\")\n",
    "\n",
    "samples = DataLoader(traindata, batch_size=16, shuffle=True)\n",
    "plot_samples(next(iter(samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244fa8c",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, depth=4, dim_latent=64, dim_img=64, in_channels=3, start_channels=64):\n",
    "        \"\"\"\n",
    "        depth: int\n",
    "            How many convolutional layers there are in the encoder/decoder\n",
    "        dim_latent: int\n",
    "            Dimension of the flattened latent space\n",
    "        dim_digit: int\n",
    "            Width/height of input image\n",
    "        in_channels: int\n",
    "            Number of channels of input image\n",
    "        start_channels: int\n",
    "            Number of channels out of the first convolutional layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        ## TODO: Fill this in\n",
    "    \n",
    "    def forward(self, X):\n",
    "        pass\n",
    "        ## TODO: Fill this in\n",
    "        \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, depth=4, dim_latent=64, dim_img=64, in_channels=3, end_channels=64):\n",
    "        \"\"\"\n",
    "        depth: int\n",
    "            How many convolutional layers there are in the encoder/decoder\n",
    "        dim_latent: int\n",
    "            Dimension of the latent space\n",
    "        dim_digit: int\n",
    "            Width/height of input image\n",
    "        in_channels: int\n",
    "            Number of channels of input image\n",
    "        end_channels: int\n",
    "            Number of channels out of the second to last convolutional layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        ## TODO: Fill this in\n",
    "    \n",
    "    def forward(self, z):\n",
    "        pass\n",
    "        ## TODO: Fill this in\n",
    "        \n",
    "    \n",
    "    def sample(self, n_examples, device):\n",
    "        \"\"\"\n",
    "        Sample from the latent space and generate the images\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_examples: int\n",
    "            Number of examples to generate\n",
    "        device: string\n",
    "            Device for model/tensors\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor(n_examples, 3, dim_img, dim_img)\n",
    "            A batch of generated examples\n",
    "        \"\"\"\n",
    "        pass\n",
    "        ## TODO: Fill this in\n",
    "    \n",
    "\n",
    "## TODO: Test your models here with dummy data before you proceed to training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de7454",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32e9bfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "depth = 2\n",
    "dim_latent = 32\n",
    "channels = 32\n",
    "lr = 3e-4\n",
    "\n",
    "n_epochs = 40\n",
    "batch_size = 16\n",
    "\n",
    "## TODO: Fill this in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e110c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
